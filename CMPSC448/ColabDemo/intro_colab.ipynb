{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "intro_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96i_3EWpqFTj",
        "colab_type": "text"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>What is Colaboratory?</h1>\n",
        "\n",
        "Colaboratory, or \"Colab\" for short, allows you to write and execute Python in your browser, with \n",
        "- Zero configuration required\n",
        "- Free access to GPU and TPU\n",
        "- Easy sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDveuPj6qVxk",
        "colab_type": "text"
      },
      "source": [
        "## **Getting started**\n",
        "\n",
        "The document you are reading is not a static web page, but an interactive environment called a **Colab notebook** that lets you write and execute code.\n",
        "\n",
        "For example, here is a **code cell** with a short Python script that computes a value, stores it in a variable, and prints the result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydAReqJdqYgT",
        "colab_type": "code",
        "outputId": "37454874-1d63-4048-b9e4-95165a542f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "seconds_in_a_day = 24 * 60 * 60\n",
        "print(seconds_in_a_day)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "86400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEsoD_OyqlZH",
        "colab_type": "text"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the play button to the left of the code, or use the keyboard shortcut \"Command/Ctrl+Enter.\" To edit the code, just click the cell and start editing.\n",
        "\n",
        "Variables that you define in one cell can later be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s29emoRRqsaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c1ba966-cac5-43f6-d941-1ac1efc90f79"
      },
      "source": [
        "seconds_in_a_week = 7 * seconds_in_a_day\n",
        "print(seconds_in_a_week)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "604800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh7h3qkrK8gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwhuzQzwMNAT",
        "colab_type": "text"
      },
      "source": [
        "We use tensorflow version 2, but in the colab the default version is 1.15; therefore, we should import the new version of tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4inrkm2mrnQy",
        "colab_type": "code",
        "outputId": "e11fce8e-4370-4c90-f392-750c0bd9bdab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGzZGV4GsZ43",
        "colab_type": "text"
      },
      "source": [
        "Now, we can checck the version of our tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvk9q4eEM6Ak",
        "colab_type": "code",
        "outputId": "91b2089e-ce50-42be-e54a-34ab4f011fc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLtGoZf4LmDF",
        "colab_type": "text"
      },
      "source": [
        "We can check that we are connected to a GPU or TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D72m-ROiLJ7Q",
        "colab_type": "code",
        "outputId": "af351645-d1c1-4c34-e44c-7cf43dd0a642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if 'COLAB_TPU_ADDR' in os.environ: \n",
        "    print('Connected to TPU') \n",
        "elif tf.test.gpu_device_name() is not '': \n",
        "    print('Connected to GPU ' + tf.test.gpu_device_name())\n",
        "else:\n",
        "    print('Neither connected to a TPU nor a GPU')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neither connected to a TPU nor a GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psZ7IJFYLwnc",
        "colab_type": "text"
      },
      "source": [
        "What is the problem? How we can use hardware accelerator?\n",
        "We should go to Runtime tab, and use \"Change the runtime type.\" In there we can use TPU or GPU as our hardware acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgqiiKNZQ9sK",
        "colab_type": "text"
      },
      "source": [
        "# Load Data\n",
        "In collab we can load data from our computer or from google drive\n",
        "## Load Data from Computer\n",
        "We can load data from our computer, so we can use these commands to upload our data in collab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_RKec03RQ4x",
        "colab_type": "code",
        "outputId": "1079bbc8-bd1e-45f9-cc72-959ca09e9620",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-866e6a88-1ff0-4645-b172-8cc00f7ba5ee\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-866e6a88-1ff0-4645-b172-8cc00f7ba5ee\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving adult.data to adult.data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxi9lqlrRYgc",
        "colab_type": "text"
      },
      "source": [
        "Now, you can click on choose file button to upload your data into colab. Then, we can save it in a dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVprBGkcRzDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io \n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['adult.data']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2ulcT-8SHIE",
        "colab_type": "text"
      },
      "source": [
        "The problem arises when we have to work with huge Dataset, as google colab also provides many ways to upload your data to its Virtual Machine on which your code is running. But as soon as you got disconnected all of your Data is lost when you reconnect to new Virtual Machine that is offered to you. To avoid this problem, we upload our data from google drive.\n",
        "\n",
        "## Load Data from Google Drive\n",
        "\n",
        "### 1.   Upload your Data to your Google Drive.\n",
        "### 2.   To mount your drive inside \"gdrive\" folder\n",
        "### 3.   You’ll see a link, click on link, then allow access, copy the code that pops up, paste it at \"Enter your authorization code:\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hT8ZNnvjUzmp",
        "colab_type": "code",
        "outputId": "715f8100-4fab-4098-9ed7-dd613ec07620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tUsRbBfVI7_",
        "colab_type": "text"
      },
      "source": [
        "Now, we have access to our google drive, we can change the directory of our project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zae_e6rdVSRE",
        "colab_type": "code",
        "outputId": "77ba5092-cbd3-4bb5-a31e-7a72cdb34f09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import os\n",
        "\n",
        "demo_folder = '/content/gdrive/My Drive/cmpsc448/colab_demo'\n",
        "\n",
        "if not os.path.exists(demo_folder):\n",
        "    os.makedirs(demo_folder)\n",
        "\n",
        "os.chdir(demo_folder)\n",
        "\n",
        "! pwd\n",
        "! ls -la"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/cmpsc448/colab_demo\n",
            "total 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiNvo4hFc5XB",
        "colab_type": "text"
      },
      "source": [
        "### 4.   Let’s say you want to read \"adult.test\". You can read the file from that folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "novb982dd6b6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('./adult.test');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYQDGU_pVDI",
        "colab_type": "text"
      },
      "source": [
        "### 5.If you want to copy the file to your google drive (In a folder) by executing this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wo-E4w7pUlQ",
        "colab_type": "code",
        "outputId": "722351a9-1db4-4314-f4f1-baf0ff45415d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!ls -la\n",
        "!cp '/content/adult.data' './'\n",
        "!ls -la"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1957\n",
            "-rw------- 1 root root 2003153 Feb  8 19:58 adult.test\n",
            "total 5838\n",
            "-rw------- 1 root root 3974305 Feb  8 20:04 adult.data\n",
            "-rw------- 1 root root 2003153 Feb  8 19:58 adult.test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bqNiBn2teMZ",
        "colab_type": "text"
      },
      "source": [
        "## Run unix commands and install packges\n",
        "\n",
        "In the google colab by putting \"!\" before your command you can run unix commands. Or, you can add '%%bash' in your cell which means that cell is a bash cell. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCjiOI0dvWFn",
        "colab_type": "code",
        "outputId": "341473a7-4005-4a98-c968-5971e30660e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pwd\n",
        "!ls -la\n",
        "!pip install scipy\n",
        "!apt install -y axel\n",
        "!axel --version"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/cmpsc448/colab_demo\n",
            "total 5838\n",
            "-rw------- 1 root root 3974305 Feb  8 20:04 adult.data\n",
            "-rw------- 1 root root 2003153 Feb  8 19:58 adult.test\n",
            "Requirement already satisfied: scipy in /tensorflow-2.1.0/python3.6 (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.1.0/python3.6 (from scipy) (1.18.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "axel is already the newest version (2.16.1-1build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Axel version 2.16.1 (Linux)\n",
            "\n",
            "Copyright 2001-2007 Wilmer van der Gaast,\n",
            "\t  2007-2009 Giridhar Appaji Nag,\n",
            "\t  2008-2010 Philipp Hagemeister,\n",
            "\t  2015-2017 Joao Eriberto Mota Filho,\n",
            "\t  2016-2017 Stephen Thirlwall,\n",
            "\t  2017      Ismael Luceno,\n",
            "\t  2017      Antonio Quartulli,\n",
            "\t\t    and others.\n",
            "Please, see the CREDITS file.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phEywmzyaJz3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "outputId": "4d5927c9-97fa-48f1-cef7-c3589976b182"
      },
      "source": [
        "%%bash\n",
        "pwd\n",
        "ls -la\n",
        "pip install scipy\n",
        "apt install -y axel\n",
        "axel --version"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/cmpsc448/colab_demo\n",
            "total 5838\n",
            "-rw------- 1 root root 3974305 Feb  8 20:04 adult.data\n",
            "-rw------- 1 root root 2003153 Feb  8 19:58 adult.test\n",
            "Requirement already satisfied: scipy in /tensorflow-2.1.0/python3.6 (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.1.0/python3.6 (from scipy) (1.18.1)\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "axel is already the newest version (2.16.1-1build1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 25 not upgraded.\n",
            "Axel version 2.16.1 (Linux)\n",
            "\n",
            "Copyright 2001-2007 Wilmer van der Gaast,\n",
            "\t  2007-2009 Giridhar Appaji Nag,\n",
            "\t  2008-2010 Philipp Hagemeister,\n",
            "\t  2015-2017 Joao Eriberto Mota Filho,\n",
            "\t  2016-2017 Stephen Thirlwall,\n",
            "\t  2017      Ismael Luceno,\n",
            "\t  2017      Antonio Quartulli,\n",
            "\t\t    and others.\n",
            "Please, see the CREDITS file.\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHUvKnf51AF",
        "colab_type": "text"
      },
      "source": [
        "## Keras\n",
        "In this section, we will talk about keras, how to import it for tensorflow 2, and how to use it in different three different API style\n",
        "- Sequential Model\n",
        "- Functional API\n",
        "- Model subclassing\n",
        "\n",
        "Consider when you want to import keras, `tf.keras` can run any Keras-compatible code, but keep in mind the `tf.keras` version in the latest TensorFlow release might not be the same as the latest keras version from PyPI. Check `tf.keras.version`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki5ntbOp4dGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-m5nNRcw8iI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is sequential API part\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential();\n",
        "model.add(layers.Dense(20, activation='relu', input_shape=(10,)))\n",
        "model.add(layers.Dense(20, activation='relu'))\n",
        "model.add(layers.Dense(20, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "#This is functional API part\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(10,))\n",
        "x = layers.Dense(20, activation='relu')(x)\n",
        "x = layers.Dense(20, activation='relu')(x)\n",
        "outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=10, batch_size=32)\n",
        "\n",
        "\n",
        "#This is for model subclassing part\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class MyModel(keras.Model):\n",
        "    def __init__:\n",
        "        super(MyModel, self).__init__()\n",
        "        self.dense1 = layers.Dense(20, activation='relu')\n",
        "        self.dense2 = layers.Dense(20, activation='relu')\n",
        "        self.dense3 = layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dense3(x)\n",
        "        return x\n",
        "\n",
        "model = MyModel()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "016B2fbbGMH2",
        "colab_type": "text"
      },
      "source": [
        "Let's see example on MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vlVqHhsGPwt",
        "colab_type": "code",
        "outputId": "63d8f600-e366-4611-ad5e-b68f643ec89d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "                                 layers.Flatten(input_shape=(28, 28)),\n",
        "                                 layers.Dense(128, activation='relu'),\n",
        "                                 layers.Dropout(0.2),\n",
        "                                 layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "\n",
        "model.evaluate(x_test,  y_test, verbose=1)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2908 - accuracy: 0.9153\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1424 - accuracy: 0.9575\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 85us/sample - loss: 0.1077 - accuracy: 0.9675\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0890 - accuracy: 0.9726\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0738 - accuracy: 0.9766\n",
            "10000/10000 [==============================] - 1s 52us/sample - loss: 0.0725 - accuracy: 0.9781\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07247910678032786, 0.9781]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8Wk7_ZlyFfn",
        "colab_type": "text"
      },
      "source": [
        "### Distributed, multi-GPU, & TPU training\n",
        "In this section we will talk about distributed and how to use them in our code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9thRSuwyR0T",
        "colab_type": "code",
        "outputId": "3533b93f-7108-4989-8c7f-80af6580582b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "import numpy as np\n",
        "\n",
        "num_samples = 1000\n",
        "height = 224\n",
        "width = 224\n",
        "num_classes = 1000\n",
        "\n",
        "# Instantiate the base model\n",
        "# It is better doing this with under a CPU device scope,\n",
        "# so that the model's weights are hosted on CPU memory.\n",
        "# Otherwise they may end up hosted on a GPU, which would\n",
        "# complicate weight sharing.\n",
        "with tf.device('/cpu:0'):\n",
        "    model = Xception(weights=None,\n",
        "                        input_shape=(height, width, 3),\n",
        "                        classes=num_classes)\n",
        "\n",
        "# Replicates the model on 8 GPUs.\n",
        "# This assumes that your machine has 8 available GPUs.\n",
        "parallel_model = multi_gpu_model(model, gpus=8)\n",
        "parallel_model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='rmsprop')\n",
        "\n",
        "# Generate dummy data.\n",
        "x = np.random.random((num_samples, height, width, 3))\n",
        "y = np.random.random((num_samples, num_classes))\n",
        "\n",
        "# This `fit` call will be distributed on 8 GPUs.\n",
        "# Since the batch size is 256, each GPU will process 32 samples.\n",
        "parallel_model.fit(x, y, epochs=20, batch_size=256)\n",
        "\n",
        "# Save model via the template model (which shares the same weights):\n",
        "model.save('my_model.h5')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-47-411d0d5f6fa1>:34: multi_gpu_model (from tensorflow.python.keras.utils.multi_gpu_utils) is deprecated and will be removed after 2020-04-01.\n",
            "Instructions for updating:\n",
            "Use `tf.distribute.MirroredStrategy` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-411d0d5f6fa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Replicates the model on 8 GPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# This assumes that your machine has 8 available GPUs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mparallel_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m parallel_model.compile(loss='categorical_crossentropy',\n\u001b[1;32m     36\u001b[0m                         optimizer='rmsprop')\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36mmulti_gpu_model\u001b[0;34m(model, gpus, cpu_merge, cpu_relocation)\u001b[0m\n\u001b[1;32m    181\u001b[0m                        \u001b[0;34m'However this machine only has: %s. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                        'Try reducing `gpus`.' % (gpus, target_devices,\n\u001b[0;32m--> 183\u001b[0;31m                                                  available_devices))\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: To call `multi_gpu_model` with `gpus=8`, we expect the following devices to be available: ['/cpu:0', '/gpu:0', '/gpu:1', '/gpu:2', '/gpu:3', '/gpu:4', '/gpu:5', '/gpu:6', '/gpu:7']. However this machine only has: ['/cpu:0', '/xla_cpu:0']. Try reducing `gpus`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILQIkAtn8NHj",
        "colab_type": "text"
      },
      "source": [
        "## CIFAR10 with Keras and CNN\n",
        "\n",
        "Let's test Keras' CNN on CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzsOC8uh8eNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XFq1fce8v3y",
        "colab_type": "code",
        "outputId": "4edc4665-c567-40a0-b64b-7b2567a33f2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "(x_train, y_train_), (x_test, y_test_) = cifar10.load_data()\n",
        "\n",
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfOD3Fv986-S",
        "colab_type": "text"
      },
      "source": [
        "### Model definition\n",
        "Now we should define our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUwOmvOI9A27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(layers.Conv2D(filters=32, \n",
        "                        kernel_size=(3, 3),\n",
        "                        activation='relu',\n",
        "                        input_shape=(32, 32, 3)))\n",
        "\n",
        "model.add(layers.MaxPool2D())\n",
        "\n",
        "model.add(layers.Conv2D(filters=64,\n",
        "                        kernel_size=(3, 3),\n",
        "                        activation='relu'))\n",
        "\n",
        "model.add(layers.MaxPool2D())\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTwXYrZeA0aW",
        "colab_type": "code",
        "outputId": "2a7628a6-d93c-4706-bd60-b01ef69705a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                23050     \n",
            "=================================================================\n",
            "Total params: 42,442\n",
            "Trainable params: 42,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZRS74uHA5dK",
        "colab_type": "code",
        "outputId": "2acb5475-5a9b-47c6-9c43-c763bafefcb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        }
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=50, epochs=15,\n",
        "                    verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/15\n",
            "50000/50000 [==============================] - 63s 1ms/sample - loss: 2.5609 - accuracy: 0.2735 - val_loss: 1.6508 - val_accuracy: 0.3899\n",
            "Epoch 2/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.5599 - accuracy: 0.4405 - val_loss: 1.4897 - val_accuracy: 0.4785\n",
            "Epoch 3/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.3496 - accuracy: 0.5247 - val_loss: 1.3200 - val_accuracy: 0.5310\n",
            "Epoch 4/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.2606 - accuracy: 0.5593 - val_loss: 1.3645 - val_accuracy: 0.5410\n",
            "Epoch 5/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.1758 - accuracy: 0.5908 - val_loss: 1.2559 - val_accuracy: 0.5738\n",
            "Epoch 6/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.0993 - accuracy: 0.6204 - val_loss: 1.1843 - val_accuracy: 0.5885\n",
            "Epoch 7/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.0506 - accuracy: 0.6356 - val_loss: 1.1743 - val_accuracy: 0.6008\n",
            "Epoch 8/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 1.0074 - accuracy: 0.6524 - val_loss: 1.1527 - val_accuracy: 0.6154\n",
            "Epoch 9/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9771 - accuracy: 0.6627 - val_loss: 1.1438 - val_accuracy: 0.6221\n",
            "Epoch 10/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9442 - accuracy: 0.6753 - val_loss: 1.1794 - val_accuracy: 0.6030\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9254 - accuracy: 0.6807 - val_loss: 1.1812 - val_accuracy: 0.6221\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9064 - accuracy: 0.6853 - val_loss: 1.2477 - val_accuracy: 0.5915\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.9049 - accuracy: 0.6864 - val_loss: 1.2662 - val_accuracy: 0.6092\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8714 - accuracy: 0.7006 - val_loss: 1.2591 - val_accuracy: 0.6122\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 62s 1ms/sample - loss: 0.8553 - accuracy: 0.7059 - val_loss: 1.2539 - val_accuracy: 0.6210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plkN1k3QBCq_",
        "colab_type": "code",
        "outputId": "0bff6f77-0a0c-4735-b1be-e282b7aa326b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['accuracy']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJC4lCBERiUsJQkRE4vr/snphPCjC0tgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QvUvZZerkZz",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation with Keras\n",
        "\n",
        "Image data augmentation is a techneuiqe that can be used to expand size of the dataset by creating modified versions of images from the dataset.\n",
        "\n",
        "Training deep neural network models on more data can result in a more skillful models. Since the augmentation techneuiqe will create different variations of the images; therefore, that can help the ability of the fit models to generalize what they have learned.\n",
        "\n",
        "The Keras deep learning neural network library provides the capability to fit models using data augmentation when we are training deep neural network.\n",
        "\n",
        "Image data augmentation is the most well known type of data augmentation which is based on rotation and transformation of the original image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OA3-h9PrSetX",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=40, \n",
        "                             width_shift_range=0.2,\n",
        "                             height_shift_range=0.2,\n",
        "                             rescale=1./255,\n",
        "                             shear_range=0.2,\n",
        "                             zoom_range=0.2,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest'\n",
        "                            )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}